{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What is Random Forest?\n",
    "\n",
    "\n",
    "In this tutorial, we are going to see how to do Random Forest using scikit learn.\n",
    "\n",
    "source:\n",
    "1. https://towardsdatascience.com/random-forest-in-python-24d0893d51c0\n",
    "2. https://towardsdatascience.com/hyperparameter-tuning-the-random-forest-in-python-using-scikit-learn-28d2aa77dd74\n",
    "3. https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestRegressor.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we load our data. The first two rows are the parameters and the third column is the dependent value."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://www.kaggle.com/enespolat/grid-search-with-logistic-regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "from sklearn.datasets import load_iris\n",
    "# print(os.listdir(\"./input\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we load out dataset.\n",
    "Note that iris dataset is s dictionary, we set x and y as the data and the target.\n",
    "And then we split the data in to test and train."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "iris=load_iris()#print(iris)\n",
    "x=iris.data # print(x.shape)\n",
    "y=iris.target # print(y.shape)\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "x_train, x_test, y_train, y_test=train_test_split(x,y,test_size=0.3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is clealy seen that there are five features for eath Iris flower data point"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[4.6 3.1 1.5 0.2]\n",
      " [6.4 2.8 5.6 2.2]\n",
      " [5.6 2.7 4.2 1.3]\n",
      " [6.1 2.6 5.6 1.4]\n",
      " [5.6 3.  4.5 1.5]]\n"
     ]
    }
   ],
   "source": [
    "print(x_train[:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Normalization (Scaling)\n",
    "Next, we apply scaling on the test dataset, and apply the same transform to the test dataset.\n",
    "After fitting, the scale and offset used with your training data is stored. We use that on the test dataset with scaler.transform.."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler = StandardScaler()\n",
    "x_train = scaler.fit_transform( x_train )\n",
    "x_test = scaler.transform( x_test )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cross Validation with Regularization\n",
    "Any model has its own hyperparameter. These paramters could change the training results significantly. Thus we have to do hyper paramter tuning via cross validation.\n",
    "\n",
    "One method is called grid search cross validation. One exhaustively navigates through the n parameters values (the grids). So we have a n squared parameter combination.\n",
    "\n",
    "The grid term is the parameter set where we include all the hyper parameters that the model uses and the range of values that we would like to test. In logistic regression, there are two hyperparameters we could tune, one is the regularization coefficient C and the second is the regularization method L.\n",
    "\n",
    "Finally, one uses K-folds cross validation to test the accuracy of the model. the cv argument in GridSearchCV allows one to decide how many folds one wants to use. an average score for each model is then generated. Only the best model and its hyperparameters are shown in the end.\n",
    "\n",
    "source:\n",
    "1. https://www.youtube.com/watch?v=IXPgm1e0IOo\n",
    "2. https://towardsdatascience.com/l1-and-l2-regularization-methods-ce25e7fc831c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 100 candidates, totalling 300 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  33 tasks      | elapsed:   11.0s\n",
      "[Parallel(n_jobs=-1)]: Done 154 tasks      | elapsed:   44.9s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tuned hpyerparameters :(best parameters)  {'n_estimators': 400, 'min_samples_split': 10, 'min_samples_leaf': 4, 'max_features': 'sqrt', 'max_depth': 90, 'bootstrap': True}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done 300 out of 300 | elapsed:  1.4min finished\n"
     ]
    }
   ],
   "source": [
    "# Simply remove warnings\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "from pprint import pprint\n",
    "# Grid search cross validation\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "n_estimators = [int(x) for x in np.linspace(start = 200, stop = 2000, num = 10)]# Number of trees in random forest\n",
    "max_features = ['auto', 'sqrt']# Number of features to consider at every split\n",
    "max_depth = [int(x) for x in np.linspace(10, 110, num = 11)]# Maximum number of levels in tree\n",
    "max_depth.append(None)\n",
    "min_samples_split = [2, 5, 10]# Minimum number of samples required to split a node\n",
    "min_samples_leaf = [1, 2, 4]# Minimum number of samples required at each leaf node\n",
    "bootstrap = [True, False]# Method of selecting samples for training each tree\n",
    "random_grid = {'n_estimators': n_estimators,\n",
    "               'max_features': max_features,\n",
    "               'max_depth': max_depth,\n",
    "               'min_samples_split': min_samples_split,\n",
    "               'min_samples_leaf': min_samples_leaf,\n",
    "               'bootstrap': bootstrap}\n",
    "\n",
    "# Use the random grid to search for best hyperparameters\n",
    "# Random search of parameters, using 3 fold cross validation, \n",
    "# search across 100 different combinations, and use all available cores\n",
    "rf = RandomForestRegressor()\n",
    "rf_random = RandomizedSearchCV(estimator = rf, param_distributions = random_grid, n_iter = 100, cv = 3, verbose=2, random_state=42, n_jobs = -1)\n",
    "# Fit the random search model\n",
    "rf_random.fit(x_train,y_train)\n",
    "print(\"tuned hpyerparameters :(best parameters) \",rf_random.best_params_)\n",
    "print(\"accuracy :\",rf_random.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy : 0.9305327755100079\n"
     ]
    }
   ],
   "source": [
    "print(\"accuracy :\",rf_random.best_score_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predictions\n",
    "Finally we do predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "score 0.9544023255938269\n"
     ]
    }
   ],
   "source": [
    "rf=RandomForestRegressor(n_estimators=400, min_samples_split=10, min_samples_leaf=4, max_features='sqrt', max_depth=90, bootstrap='True')\n",
    "rf.fit(x_train,y_train)\n",
    "print(\"score\",rf.score(x_test,y_test))\n",
    "                         "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### P.S.1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One could manually find the cv scores by the following lines. This example shows when we have selected C=1 and L2 morn as regularization, the average score of the 10 folds cross validation is 94.25%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9425252525252527\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "print(cross_val_score(LogisticRegression(C=1,penalty=\"l2\"), x_train, y_train, scoring='accuracy', cv = 10).mean())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
